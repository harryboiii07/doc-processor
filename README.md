# Django Excel to JSON Conversion Service

A high-performance Django REST API service that converts large Excel files (XLSX/XLS) to JSON format for n8n workflow integration. The service handles large files efficiently through streaming and batching, with comprehensive logging for production monitoring.

## üöÄ Features

- **Single Endpoint**: POST `/api/convert-excel` for file conversion
- **High Performance**: Streaming processing with batching (1000 rows per batch)
- **Large File Support**: Handles files up to 100MB efficiently
- **Multiple Formats**: Supports both .xlsx and .xls files
- **Memory Efficient**: Uses read-only mode and lazy evaluation
- **Comprehensive Logging**: Structured JSON logging for Grafana integration
- **Production Ready**: Docker support with health checks
- **Error Handling**: Graceful handling of corrupted files and memory errors

## üìã Requirements

- Python 3.11+
- Django 4.2+
- Django REST Framework 3.14+
- openpyxl 3.1+ (for .xlsx files)
- xlrd 2.0+ (for .xls files)
- python-magic 0.4.27+ (for file type validation)
- gunicorn 21.2+ (for production)
- psutil 5.9+ (for system monitoring)

## üõ† Installation & Setup

### Local Development

1. **Clone and setup virtual environment:**
```bash
cd /path/to/your/project
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

2. **Run database migrations:**
```bash
python manage.py migrate
```

3. **Start development server:**
```bash
python manage.py runserver
```

The service will be available at `http://localhost:8000`

### Docker Deployment

1. **Build and run with Docker Compose:**
```bash
docker-compose up --build
```

2. **For production with Nginx:**
```bash
docker-compose --profile production up --build
```

## üì° API Endpoints

### Convert Excel to JSON
```
POST /api/convert-excel
Content-Type: multipart/form-data
```

**Request:**
- `file`: Excel file (.xlsx or .xls, max 100MB)

**Success Response (200 OK):**
```json
{
    "success": true,
    "data": [
        {
            "‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡∏û‡∏¥‡∏ô‡∏ô‡∏≤‡πÄ‡∏Ñ‡∏¥‡∏• ‡πÇ‡∏ö‡∏£‡∏Å‡πÄ‡∏Å‡∏≠‡∏£‡πå‡πÄ‡∏£‡∏à ‡∏à‡∏≥‡∏Å‡∏±‡∏î RSA48834 DUE 29082025": "NO.",
            "__EMPTY": "POLICY NO.",
            "__EMPTY_1": "INSURE NAME"
        },
        {
            "‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡∏û‡∏¥‡∏ô‡∏ô‡∏≤‡πÄ‡∏Ñ‡∏¥‡∏• ‡πÇ‡∏ö‡∏£‡∏Å‡πÄ‡∏Å‡∏≠‡∏£‡πå‡πÄ‡∏£‡∏à ‡∏à‡∏≥‡∏Å‡∏±‡∏î RSA48834 DUE 29082025": 1,
            "__EMPTY": "77853616",
            "__EMPTY_1": "‡∏Ñ‡∏∏‡∏ì ‡∏ô‡∏¥‡∏®‡∏≤‡∏ä‡∏• ‡∏®‡∏¥‡∏•‡∏≤‡πÄ‡∏ì‡∏£"
        }
    ],
    "metadata": {
        "total_rows": 1500,
        "processing_time": 12.34,
        "file_size": "2.5MB",
        "worksheet_name": "Sheet1",
        "file_type": "XLSX",
        "batch_size": 1000,
        "performance": {
            "rows_per_second": 121.35,
            "peak_memory_mb": 45.2,
            "total_batches": 2
        }
    }
}
```

**Error Response (400/422/500):**
```json
{
    "success": false,
    "error": {
        "code": "PROCESSING_ERROR",
        "message": "Failed to process Excel file",
        "details": "Specific error description"
    }
}
```

### Health Check
```
GET /health
```

**Response (200 OK):**
```json
{
    "status": "healthy",
    "timestamp": "2025-01-01T12:00:00Z",
    "version": "1.0.0",
    "memory_usage": "45.2%",
    "system_info": {
        "cpu_usage": "12.5%",
        "memory_mb": 128.5,
        "available_memory_mb": 2048.0
    },
    "service_info": {
        "max_file_size_mb": 100,
        "supported_formats": [".xlsx", ".xls"],
        "batch_size": 1000
    }
}
```

### Service Information
```
GET /api/info
```

Returns detailed service configuration and system information.

## üß™ Testing Examples

### cURL Commands

1. **Convert Excel file:**
```bash
curl -X POST \
  http://localhost:8000/api/convert-excel \
  -H "Content-Type: multipart/form-data" \
  -F "file=@/path/to/your/file.xlsx"
```

2. **Health check:**
```bash
curl http://localhost:8000/health
```

3. **Service info:**
```bash
curl http://localhost:8000/api/info
```

### Python Testing Script

```python
import requests

# Test file conversion
def test_excel_conversion():
    url = "http://localhost:8000/api/convert-excel"
    
    with open("test_file.xlsx", "rb") as f:
        files = {"file": f}
        response = requests.post(url, files=files)
    
    if response.status_code == 200:
        data = response.json()
        print(f"Success! Processed {data['metadata']['total_rows']} rows")
        print(f"Processing time: {data['metadata']['processing_time']}s")
    else:
        print(f"Error: {response.status_code}")
        print(response.json())

# Test health check
def test_health():
    response = requests.get("http://localhost:8000/health")
    print("Health:", response.json())

if __name__ == "__main__":
    test_health()
    test_excel_conversion()
```

### Performance Testing

For testing with large files:

```bash
# Test with different file sizes
curl -X POST \
  http://localhost:8000/api/convert-excel \
  -H "Content-Type: multipart/form-data" \
  -F "file=@large_file_10mb.xlsx" \
  -w "Time: %{time_total}s\n"
```

## üîß Configuration

### Environment Variables

- `SECRET_KEY`: Django secret key (required for production)
- `DEBUG`: Enable debug mode (default: True)
- `ALLOWED_HOSTS`: Comma-separated list of allowed hosts
- `APP_VERSION`: Application version (default: 1.0.0)
- `CORS_ALLOWED_ORIGINS`: CORS allowed origins (optional)
- `CORS_ALLOW_ALL_ORIGINS`: Allow all CORS origins (default: False)

### Production Settings

For production deployment, set these environment variables:

```bash
export SECRET_KEY="your-secure-secret-key"
export DEBUG=False
export ALLOWED_HOSTS="yourdomain.com,api.yourdomain.com"
export APP_VERSION="1.0.0"
```

## üìä Logging & Monitoring

### Log Formats

The service uses structured JSON logging compatible with Grafana:

```json
{
    "timestamp": "2025-01-01T12:00:00.000Z",
    "level": "INFO",
    "logger": "converter",
    "message": "Processing completed",
    "module": "views",
    "function": "post",
    "line": 123
}
```

### Log Files

- `logs/excel_converter.log`: General application logs (50MB, 10 backups)
- `logs/excel_converter_errors.log`: Error-only logs (50MB, 5 backups)

### Key Metrics Logged

- Request received: file size, file type, timestamp
- Processing started: batch count, estimated processing time
- Batch processing: current batch number, progress percentage
- Memory usage: current memory consumption per batch
- Processing completed: total rows processed, processing time
- Performance metrics: processing speed (rows/second), memory peak usage

### Grafana Integration

Use these log queries for monitoring:

```
# Processing time by file size
avg(processing_time) by (file_size_mb)

# Error rate
rate(log_entries{level="ERROR"}[5m])

# Memory usage trends
avg(peak_memory_mb) by (file_type)

# Throughput
sum(rate(total_rows[5m]))
```

## üö® Error Handling

### Error Codes

- `VALIDATION_ERROR`: Invalid request data or file format
- `PROCESSING_ERROR`: Excel file processing failed
- `MEMORY_ERROR`: File too large for available memory
- `INTERNAL_ERROR`: Unexpected server error

### Common Issues

1. **File too large**: Reduce file size or increase server memory
2. **Corrupted Excel file**: Verify file integrity
3. **Unsupported format**: Use .xlsx or .xls files only
4. **Memory errors**: Process smaller batches or increase system memory

## üîí Security Considerations

- File type validation using python-magic (not just extensions)
- File size limits enforced at multiple levels
- Non-root user in Docker containers
- CSRF protection enabled
- XSS and content-type protection headers

## üöÄ Performance Optimization

### Memory Management

- Read-only mode for Excel files
- Streaming processing with configurable batch sizes
- Lazy evaluation to minimize memory footprint
- Temporary file cleanup

### Processing Speed

- Optimized for large files (tested up to 100MB)
- Batch processing prevents memory overflow
- Efficient data type handling
- Progress tracking and monitoring

## üìà Benchmarks

Typical performance on standard hardware:

- **Small files** (< 1MB): ~500-1000 rows/second
- **Medium files** (1-10MB): ~200-500 rows/second  
- **Large files** (10-100MB): ~100-300 rows/second

Memory usage typically peaks at 2-3x the input file size.

## üêõ Troubleshooting

### Common Issues

1. **Import errors**: Ensure all dependencies are installed
2. **Permission errors**: Check file permissions in Docker
3. **Memory errors**: Increase Docker memory limits
4. **Timeout errors**: Increase gunicorn timeout settings

### Debug Mode

Enable debug logging:

```python
# In settings.py
LOGGING['loggers']['converter']['level'] = 'DEBUG'
```

### Health Check Failures

Check the health endpoint for system status:

```bash
curl http://localhost:8000/health
```

## üìù License

This project is licensed under the MIT License.

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## üìû Support

For issues and questions:

1. Check the logs in `logs/` directory
2. Verify system requirements
3. Test with the health check endpoint
4. Review the troubleshooting section
